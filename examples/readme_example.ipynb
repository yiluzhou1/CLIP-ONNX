{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lednik7/CLIP-ONNX/blob/main/examples/readme_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "whlsBiJgR8le"
      },
      "source": [
        "## Restart colab session after installation\n",
        "Reload the session if something doesn't work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HnbpAkvuR73L"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/Lednik7/CLIP-ONNX.git\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install onnxruntime-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tqy0zKM4R-7M"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget -c -O CLIP.png https://github.com/openai/CLIP/blob/main/CLIP.png?raw=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKqETHL4YscZ",
        "outputId": "7ff0bc18-fb40-4296-ab05-b079043e46a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi # CPU Provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8IN72OnSAIh",
        "outputId": "81d14047-91fa-4a5c-a1e3-f5b550556591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU\n"
          ]
        }
      ],
      "source": [
        "import onnxruntime\n",
        "\n",
        "print(onnxruntime.get_device()) # priority device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U1Pr-YTtSEhs"
      },
      "source": [
        "## CPU inference mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gZTxanR26knr"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rPwc6A2SSGyl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLIP ONNX] Start convert visual model\n",
            "[CLIP ONNX] Start check visual model\n",
            "[CLIP ONNX] Start convert textual model\n",
            "[CLIP ONNX] Start check textual model\n",
            "[CLIP ONNX] Models converts successfully\n",
            "Label probs: [[0.08915787 0.90815187 0.00269029]]\n"
          ]
        }
      ],
      "source": [
        "import clip\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# onnx cannot export with cuda\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=\"cpu\", jit=False)\n",
        "\n",
        "# batch first\n",
        "image = preprocess(Image.open('/mnt/eds_share/share/Spine2D/GlobusSrgMapData_crop_square/test/images/anon_d4730414.dcm_lateral_full_lumbar_thoracic.jpg')).unsqueeze(0).cpu() # [1, 3, 224, 224]\n",
        "image_onnx = image.detach().cpu().numpy().astype(np.float32)\n",
        "\n",
        "# batch first\n",
        "text = clip.tokenize([\"MRI\", \"Xray\", \"CT\"]).cpu() # [3, 77]\n",
        "text_onnx = text.detach().cpu().numpy().astype(np.int32)\n",
        "\n",
        "from clip_onnx import clip_onnx\n",
        "\n",
        "visual_path = \"clip_visual.onnx\"\n",
        "textual_path = \"clip_textual.onnx\"\n",
        "\n",
        "onnx_model = clip_onnx(model, visual_path=visual_path, textual_path=textual_path)\n",
        "onnx_model.convert2onnx(image, text, verbose=True)\n",
        "# ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
        "onnx_model.start_sessions(providers=[\"CPUExecutionProvider\"]) # cpu mode\n",
        "\n",
        "image_features = onnx_model.encode_image(image_onnx)\n",
        "text_features = onnx_model.encode_text(text_onnx)\n",
        "\n",
        "logits_per_image, logits_per_text = onnx_model(image_onnx, text_onnx)\n",
        "probs = logits_per_image.softmax(dim=-1).detach().cpu().numpy()\n",
        "\n",
        "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421067 0.00299571]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYM5FDSGSJBW",
        "outputId": "816705b1-3829-4424-c7c4-5426cf21cc18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLIP ONNX] Start convert visual model\n",
            "[CLIP ONNX] Start check visual model\n",
            "[CLIP ONNX] Start convert textual model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda/envs/yz_openclip/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:5856: UserWarning: Exporting aten::index operator of advanced indexing in opset 14 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLIP ONNX] Start check textual model\n",
            "[CLIP ONNX] Models converts successfully\n",
            "Label probs: [[0.01968996 0.93325    0.04706011]]\n"
          ]
        }
      ],
      "source": [
        "import open_clip\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from clip_onnx import clip_onnx\n",
        "\n",
        "# onnx cannot export with cuda\n",
        "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k', device=\"cpu\", jit=False)\n",
        "\n",
        "# batch first\n",
        "image = preprocess(Image.open('/mnt/eds_share/share/Spine2D/GlobusSrgMapData_crop_square/test/images/anon_d4730414.dcm_lateral_full_lumbar_thoracic.jpg')).unsqueeze(0).cpu() # [1, 3, 224, 224]\n",
        "image_onnx = image.detach().cpu().numpy().astype(np.float32)\n",
        "\n",
        "# batch first\n",
        "text = open_clip.tokenize([\"MRI\", \"Xray\", \"CT\"]).cpu() # [3, 77]\n",
        "text_onnx = text.detach().cpu().numpy().astype(np.int64)\n",
        "\n",
        "visual_path = \"clip_visual.onnx\"\n",
        "textual_path = \"clip_textual.onnx\"\n",
        "\n",
        "onnx_model = clip_onnx(model, visual_path=visual_path, textual_path=textual_path, openclip=\"openclip\")\n",
        "onnx_model.convert2onnx(image, text, verbose=True)\n",
        "# ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
        "onnx_model.start_sessions(providers=[\"CPUExecutionProvider\"]) # cpu mode\n",
        "\n",
        "image_features = onnx_model.encode_image(image_onnx)\n",
        "text_features = onnx_model.encode_text(text_onnx)\n",
        "\n",
        "logits_per_image, logits_per_text = onnx_model(image_onnx, text_onnx)\n",
        "probs = logits_per_image.softmax(dim=-1).detach().cpu().numpy()\n",
        "\n",
        "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421067 0.00299571]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYVuk72nSLw6",
        "outputId": "41608059-3732-4ea7-c619-66f803af4185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label probs: [[0.08915787 0.90815187 0.00269029]]\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPpME0Qdi/m3VZQ+jNj39dT",
      "include_colab_link": true,
      "name": "readme_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
